audio:
  sample_rate: 16000
  channels: 1
  chunk_ms: 30                  # frame size for VAD (10, 20, or 30 ms)
  dtype: "int16"

wake_word:
  engine: "openwakeword"
  # Path to custom .onnx model or built-in name
  # To train custom: https://github.com/dscripka/openwakeword#training-custom-models
  # If no model provided, it will wait for "hey jarvis"
  model_path: "models/openwakeword/andromeda.onnx"
  threshold: 0.5                # detection confidence threshold (0.0 - 1.0)

vad:
  aggressiveness: 3             # 0-3, higher = more aggressive noise filtering
  silence_timeout_sec: 1.5
  speech_pad_ms: 300            # padding before/after speech segments
  max_recording_sec: 30
  min_recording_sec: 0.5
  energy_threshold_factor: 0.6  # threshold = calibrated_speech_energy * this factor
  energy_decay_rate: 0.98       # per-second decay of energy threshold

noise:
  enabled: false
  stationary: true              # true for constant background noise (fan, AC)
  prop_decrease: 0.75           # how much to reduce noise (0.0-1.0)

stt:
  engine: "faster-whisper"
  model_size: "medium"          # tiny, base, small, medium, large-v3
  device: "auto"                # auto, cpu, cuda
  compute_type: "int8"          # float16, int8 (int8 good for Apple Silicon)
  language: "it"
  beam_size: 1
  vad_filter: false             # whisper's built-in VAD for better accuracy

agent:
  provider: "ollama"
  base_url: "http://localhost:11434"
  model: "gpt-oss:20b"
  max_tokens: 500
  streaming: true               # true = speak sentence-by-sentence as LLM generates (lower latency)
  prewarm: true                 # pre-warm model at startup to avoid cold start on first request
  system_prompt: |
    Sei un assistente vocale domestico intelligente. Ti chiami Andromeda.
    Rispondi in italiano, in modo conciso e naturale.
    Le tue risposte verranno lette ad alta voce, quindi:
    - Usa frasi brevi e chiare
    - Evita formattazione markdown, elenchi puntati, simboli speciali
    - Non usare abbreviazioni ambigue
    - Quando dai numeri, scrivi la forma parlata (es. "duemila" non "2000")

tts:
  engine: "kokoro"              # piper - kokoro
  piper_model_path: "models/piper/it_IT-paola-medium.onnx"
  piper_model_config: "models/piper/it_IT-paola-medium.onnx.json"
  kokoro_lang_code: "i"
  kokoro_voice: "if_sara"
  kokoro_speed: 1.2
  speaker_id: 0
  length_scale: 1.3             # speech speed (1.0 normal, 1.3 slower, 0.8 faster)
  sentence_silence: 0.5         # pause between sentences in seconds
  prewarm_cache: true           # pre-synthesize common error phrases at startup

conversation:
  follow_up_timeout_sec: 5.0    # seconds to wait for follow-up after response (0 = disabled)
  history_timeout_sec: 300.0    # clear conversation history after N seconds of inactivity (0 = never)

tools:
  knowledge_base_path: "data/knowledge.json"
  weather_timeout_sec: 10.0
  timer_max_sec: 3600
  web_search_timeout_sec: 10.0        # timeout HTTP per la ricerca web
  web_search_max_results: 3           # numero di risultati da restituire
  web_search_max_content_chars: 2000  # max caratteri dal contenuto della pagina
  web_search_fetch_page_content: false # scarica il contenuto completo del primo risultato

feedback:
  wake_sound: "sounds/wake.wav"
  done_sound: "sounds/done.wav"
  error_sound: "sounds/error.wav"
  thinking_sound: "sounds/thinking.wav"
  thinking_volume: 0.3

health_check:
  enabled: false                # enable HTTP health check endpoint
  host: "0.0.0.0"
  port: 8080                    # GET http://localhost:8080/ for status JSON

logging:
  level: "INFO" # DEBUG, INFO, WARNING, ERROR
